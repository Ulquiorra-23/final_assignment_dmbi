{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert Data Cleaning Part from Juanjo\n",
    "\n",
    "#-----------FOR THE BOIS----------------------\n",
    "\n",
    "#--------LIBRARIES FOR THE BOIS (THE ONES I USED, THE USUAL ONES)-----------\n",
    "\n",
    "#COOL LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------FUNCTIONS FOR THE BOIS-----------\n",
    "\n",
    "#CREATE DATAFRAMES FUNCTION\n",
    "#Creates 3 super cool dataframes from the CSVs with the data types set from the start.\n",
    "def dataFrameCreate():\n",
    "    global sales_phases_funnel_df, zipcode_df, meteo_df\n",
    "\n",
    "    # SET PATHS OF 3 COOL CSVs\n",
    "    FILENAME_sales_phases_funnel_df = os.path.join(os.getcwd(), r'data/sale_phases_funnel.csv')\n",
    "    FILENAME_zipcode_df = os.path.join(os.getcwd(), r'data/zipcode_eae.csv')\n",
    "    FILENAME_meteo_df = os.path.join(os.getcwd(), r'data/meteo_eae.csv')\n",
    "\n",
    "\n",
    "    #SALES FUNNEL DATAFRAME\n",
    "\n",
    "    #Dictionary with data types\n",
    "    SALES_TYPES = {'LEAD_ID':'str','FINANCING_TYPE':'str',\n",
    "                    'CURRENT_PHASE':'str','PHASE_PRE_KO':'str',\n",
    "                    'IS_MODIFIED':'bool','ZIPCODE':'str', \n",
    "                    'VISITING_COMPANY': 'str', 'KO_REASON': 'str', \n",
    "                    'INSTALLATION_PEAK_POWER_KW': 'float64', \n",
    "                    'INSTALLATION_PRICE': 'float', \n",
    "                    'N_PANELS': 'int', 'CUSOMER_TYPE': 'str' }\n",
    "\n",
    "    # Reading CSV to create dataframe with datatypes implemented from dictionary and additional date time datatypes.\n",
    "    sales_phases_funnel_df = pd.read_csv(\n",
    "        FILENAME_sales_phases_funnel_df, \n",
    "        delimiter=';', \n",
    "        dtype=SALES_TYPES,\n",
    "        parse_dates=['OFFER_SENT_DATE', 'CONTRACT_1_DISPATCH_DATE', \n",
    "                    'CONTRACT_2_DISPATCH_DATE', \n",
    "                    'CONTRACT_1_SIGNATURE_DATE', \n",
    "                    'CONTRACT_2_SIGNATURE_DATE',\n",
    "                    'VISIT_DATE',\n",
    "                    'TECHNICAL_REVIEW_DATE',\n",
    "                    'PROJECT_VALIDATION_DATE',\n",
    "                    'SALE_DISMISSAL_DATE',\n",
    "                    'KO_DATE'],\n",
    "                    \n",
    "        dayfirst=True  # This replaces the dayfirst=True in your to_datetime call\n",
    "    )\n",
    "\n",
    "    print('sales_phases_funnel_df created')\n",
    "\n",
    "\n",
    "\n",
    "    #ZIPCODE DATAFRAME\n",
    "\n",
    "    #Dictionary with data types\n",
    "    ZIPCODE_TYPES = {'ZIPCODE':'str','ZC_LATITUDE':'float64',\n",
    "                    'ZC_LONGITUDE':'float64','AUTONOMOUS_COMMUNITY':'str',\n",
    "                    'AUTONOMOUS_COMMUNITY_NK':'str','PROVINCE':'str'}\n",
    "\n",
    "\n",
    "    # Reading CSV to create dataframe with datatypes implemented from dictionary\n",
    "    zipcode_df = pd.read_csv(FILENAME_zipcode_df, delimiter=',', dtype=ZIPCODE_TYPES)\n",
    "\n",
    "\n",
    "    print('zipcodedf created')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #METEO DATAFRAME\n",
    "\n",
    "    #Dictionary with data types\n",
    "    METEO_TYPES = {'temperature': 'float', 'relative_humidity': 'float', \n",
    "                'precipitation_rate': 'float', 'wind_speed': 'float', \n",
    "                'zipcode': 'str' \n",
    "    }\n",
    "\n",
    "    # Reading CSV to create dataframe with datatypes implemented from dictionary and \n",
    "    # additional date time datatype formatted to match the ones from the sales dataframe.\n",
    "    meteo_df = pd.read_csv(FILENAME_meteo_df, delimiter=';',\n",
    "        dtype=METEO_TYPES, parse_dates=['date'],  # Replace with actual column name\n",
    "        date_format='%Y/%m/%d %H:%M:%S.%f'  # This matches your input format\n",
    "    )\n",
    "\n",
    "    print('meteo_df created')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "dataFrameCreate()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--GLOBAL CLEANING FUNCTION--\n",
    "\n",
    "\n",
    "#DROPPING DUPLICATES FOR ALL DATAFRAMES\n",
    "\n",
    "#creating the drop duplicate function\n",
    "def dropDupli():\n",
    "    global sales_phases_funnel_df, zipcode_df, meteo_df\n",
    "    print('There are ', sales_phases_funnel_df.duplicated().sum(), ' duplicate rows in sales_funnel_df before duplicate cleaning') \n",
    "    print('There are ', zipcode_df.duplicated().sum(), ' duplicate rows in zipcode_df before duplicate cleaning')\n",
    "    print('There are ', meteo_df.duplicated().sum(), ' duplicate rows in meteo_df before duplicate cleaning') \n",
    "    sales_phases_funnel_df.drop_duplicates(inplace=True)\n",
    "    zipcode_df.drop_duplicates(inplace=True)\n",
    "    meteo_df.drop_duplicates(inplace=True)\n",
    "    print('There are ', sales_phases_funnel_df.duplicated().sum(), ' duplicate rows in sales_funnel_df after duplicate cleaning') \n",
    "    print('There are ', zipcode_df.duplicated().sum(), ' duplicate rows in zipcode_df after duplicate cleaning')\n",
    "    print('There are ', meteo_df.duplicated().sum(), ' duplicate rows in meteo_df after duplicate cleaning')\n",
    "\n",
    "dropDupli()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --SALES FUNNEL DATAFRAME CLEANING FUCTIONS--\n",
    "\n",
    "\n",
    "#DELETE UNUSABLE LEADS FUNCTION \n",
    "\n",
    "# Drop rows where KO_REASON is \"Unreachable\"\n",
    "def delete_unreachable_leads():\n",
    "    global sales_phases_funnel_df\n",
    "    sales_phases_funnel_df = sales_phases_funnel_df[~((sales_phases_funnel_df['CURRENT_PHASE'] == 'KO') & (sales_phases_funnel_df['KO_REASON'] == 'Unreachable'))]\n",
    "    # Reset the index of the updated DataFrame\n",
    "    sales_phases_funnel_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "#print(sales_phases_funnel_df.isnull().sum())\n",
    "#print(sales_phases_funnel_df.head())\n",
    "\n",
    "delete_unreachable_leads()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# REMOVE OUTLIERS FUNCTION\n",
    "\n",
    "\n",
    "def delete_outliers():\n",
    "    global sales_phases_funnel_df, outliers_df\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    Q1 = sales_phases_funnel_df['INSTALLATION_PRICE'].quantile(0.25)\n",
    "    Q3 = sales_phases_funnel_df['INSTALLATION_PRICE'].quantile(0.75)\n",
    "\n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Identify outliers inside a new Data Frame\n",
    "    outliers_df = sales_phases_funnel_df[(sales_phases_funnel_df['INSTALLATION_PRICE'] < (Q1 - 1.5 * IQR)) | \n",
    "                                     (sales_phases_funnel_df['INSTALLATION_PRICE'] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "    # Print the number of outliers\n",
    "    print('outliers_df created')\n",
    "    print(f'Number of outliers: {len(outliers_df)}')\n",
    "    \n",
    "    # Update sales_phases_funnel_df to exclude the outliers\n",
    "    sales_phases_funnel_df = sales_phases_funnel_df[~((sales_phases_funnel_df['INSTALLATION_PRICE'] < (Q1 - 1.5 * IQR)) | \n",
    "                                                  (sales_phases_funnel_df['INSTALLATION_PRICE'] > (Q3 + 1.5 * IQR)))]\n",
    "    print('outliers removed from sales_phases_funnel_df')\n",
    "    \n",
    "\n",
    "\n",
    "delete_outliers()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------DATAFRAMES FOR THE BOIS-------\n",
    "\n",
    "\n",
    "#This is the final list of dataframes\n",
    "list_of_dfs = [sales_phases_funnel_df, zipcode_df, meteo_df, outliers_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------Transformations---------- ##\n",
    "\n",
    "# Rename Data Frames\n",
    "\n",
    "sales_fact_df=sales_phases_funnel_df\n",
    "zipcode_dim_df=zipcode_df\n",
    "weather_dim_df=meteo_df\n",
    "\n",
    "# All column names in lower case letters\n",
    "\n",
    "sales_fact_df.columns= sales_fact_df.columns.str.lower()\n",
    "zipcode_dim_df.columns= zipcode_dim_df.columns.str.lower()\n",
    "weather_dim_df.columns= weather_dim_df.columns.str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zipcode_id in zipcode_dim_df\n",
    "\n",
    "zipcode_dim_df.insert(0,\"zipcode_id\",range(1, len(zipcode_dim_df) + 1))\n",
    "zipcode_dim_df[\"zipcode_id\"] = zipcode_dim_df[\"zipcode_id\"].astype(\"int32\")\n",
    "zipcode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge zipcode_dim and weather_dim\n",
    "\n",
    "weather_dim_df = pd.merge(weather_dim_df,zipcode_dim_df,on= \"zipcode\", how=\"left\")\n",
    "weather_dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge zipcode_dim and sales_fact\n",
    "\n",
    "sales_fact_df = pd.merge(sales_fact_df, zipcode_dim_df, on=\"zipcode\", how=\"left\")\n",
    "sales_fact_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weather_id in weather_dim\n",
    "\n",
    "weather_dim_df.insert(0,\"weather_id\",range(1, len(weather_dim_df) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sales_id to sales_fact\n",
    "\n",
    "sales_fact_df.insert(0,\"sales_id\",range(1, len(sales_fact_df) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add calculated column to sales_fact_df\n",
    "\n",
    "sales_fact_df.insert(16,\"most_recent_contract_signature\",sales_fact_df[[\"contract_1_signature_date\", \"contract_2_signature_date\"]].max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Arrangement of columns for sales_fact_df\n",
    "\n",
    "FINAL_COLS_SALES = [\"sales_id\",\"zipcode_id\",\"lead_id\",\"financing_type\",\"current_phase\",\"phase_pre_ko\",\n",
    "              \"is_modified\",\"offer_sent_date\",\"contract_1_dispatch_date\",\"contract_2_dispatch_date\",\"contract_1_signature_date\",\n",
    "              \"contract_2_signature_date\",\"most_recent_contract_signature\",\"visit_date\",\"technical_review_date\",\n",
    "              \"project_validation_date\",\"sale_dismissal_date\",\"ko_date\",\"visiting_company\",\"ko_reason\",\n",
    "              \"installation_peak_power_kw\",\"installation_price\",\"n_panels\",\"cusomer_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date to year, rename columns in and final arrangement of columns in weather_dim_df\n",
    "\n",
    "weather_dim_df['date'] = weather_dim_df['date'].dt.year\n",
    "\n",
    "weather_dim_df= weather_dim_df.rename(columns={\"date\":\"year\",'temperature': 'avg_temperature', 'relative_humidity': 'avg_relative_humidity',\n",
    "                                               \"precipitation_rate\":\"avg_precipitation_rate\",\"wind_speed\":\"avg_wind_speed\"})\n",
    "\n",
    "\n",
    "\n",
    "FINAL_COLS_WEATHER=[\"weather_id\",\"zipcode_id\",\"year\",\"avg_temperature\",\"avg_relative_humidity\",\"avg_precipitation_rate\",\n",
    "                    \"avg_wind_speed\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dim_df=weather_dim_df[FINAL_COLS_WEATHER]\n",
    "\n",
    "weather_dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_fact_df=sales_fact_df[FINAL_COLS_SALES]\n",
    "sales_fact_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do:\n",
    "\n",
    "# Group weather table by zipcode id \n",
    "# Create zipcode id in zipcode_dim\n",
    "# Merge zipcode and weather \n",
    "# merge zipcode and fact\n",
    "# add weather id in weather_dim done \n",
    "# add sales id to sales done\n",
    "# columns\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
